# Cloudy Light Project
Welcome to the Cloudy Light project! This repository provides a distributed computing solution using Docker, Kubernetes, and RabbitMQ for efficient data processing and analysis.

File Structure

ðŸ“‚ project-root/

â”‚â”€â”€ ðŸ“‚ k8s/                     # Kubernetes Deployment Files

â”‚   â”œâ”€â”€ final-analysis-deployment.yaml   # K8s configuration for final-analysis task

â”‚   â”œâ”€â”€ drawer-deployment.yaml           # K8s configuration for drawer task

â”‚   â”œâ”€â”€ data-processor-deployment.yaml   # K8s configuration for data-processor message queue

â”‚   â”œâ”€â”€ rabbitmq-service.yaml            # RabbitMQ Service configuration

â”‚   â”œâ”€â”€ rabbitmq-deployment.yaml         # K8s configuration for RabbitMQ message queue

â”‚â”€â”€ ðŸ“‚ Data_Processor/                  # Automation Scripts

â”‚   â”œâ”€â”€ app.py                           # Python code for preprocessing data

â”‚   â”œâ”€â”€ Dockerfile                       

â”‚   â”œâ”€â”€ requirements.txt                # Required environment

â”‚â”€â”€ ðŸ“‚ Final_Analysis/                   # Configuration Files

â”‚   â”œâ”€â”€ app.py                           # Python code for data computation

â”‚   â”œâ”€â”€ Dockerfile                       

â”‚   â”œâ”€â”€ requirements.txt                # Required environment

â”‚â”€â”€ ðŸ“‚ visualizer-outcome/               # Configuration Files

â”‚   â”œâ”€â”€ app.py                           # Python code for visualization

â”‚   â”œâ”€â”€ Dockerfile                       

â”‚   â”œâ”€â”€ requirements.txt                # Required environment

â”‚â”€â”€ README.md                            # Running and Deployment Instructions

â”‚â”€â”€ requirements.txt                     # Python dependency libraries

â”‚â”€â”€ docker-compose.yaml                  # For local testing

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”prepareâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

Running and Usage Instructions

Prerequisites

Docker

Kubernetes (kubectl)

RabbitMQ (optional for local testing)

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”runningâ€”â€”â€”â€”â€”â€”â€”â€”

Build Docker Images

```python
docker build -t username/data_processor:latest ./Data_Processor
```
```python
docker build -t username/final-analysis:latest ./Final_Analysis
```
```python
docker build -t username/drawer:latest ./visualizer-outcome
```
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”Push Docker Images to Registryâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
```python
docker push username/data_processor:latest
```
```python
docker push username/final-analysis:latest
```
```python
docker push username/drawer:latest
```
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”Deploy to Kubernetesâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
```python
kubectl apply -f ./k8s
```
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”Check Pod Statusâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
```python
kubectl get pods
```
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”Access RabbitMQ Management Interfaceâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

kubectl port-forward svc/rabbitmq 15672:15672

Open http://localhost:15672 in your browser and log in with admin/password123.

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”Clean Upâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

To delete all deployed resources, run:

```python
kubectl delete all --all
```
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”Project Overviewâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

This project is designed to handle large-scale data processing using a distributed computing approach. It leverages Docker for containerization, Kubernetes for orchestration, and RabbitMQ for message passing. The system is divided into three main components:

Data Processor: Handles data preprocessing and sends processed data to the message queue.

Final Analysis: Performs computations on the preprocessed data.

Visualizer: Generates visualizations from the computed data.

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”Features â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

Scalability: Easily scale the number of containers using Kubernetes.

Efficiency: Parallel processing of data using multiple containers.

Flexibility: Supports different data sources and processing tasks.

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”Future Workâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

Improve data flow monitoring to prevent message congestion.

Enhance fault tolerance for network issues and data processing errors.

Implement data encryption for secure handling of sensitive information.



